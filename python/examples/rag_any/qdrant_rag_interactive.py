#!/usr/bin/env python3
"""
äº¤äº’å¼ RAG-Anything ç³»ç»Ÿ
æ”¯æŒå¤šæ¨¡æ€æ–‡æ¡£çš„æ™ºèƒ½æ£€ç´¢å’Œé—®ç­”
åŸºäº RAG-Anything æ¡†æ¶æ„å»º
"""

import os
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
from attrs import define, field
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
import httpx
from datetime import datetime
import logging
import numpy as np

# å¯¼å…¥ RAG-Anything æ ¸å¿ƒç»„ä»¶
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.utils import EmbeddingFunc

# é¿å…ä»£ç†é—®é¢˜
os.environ['NO_PROXY'] = 'localhost,127.0.0.1,::1'
os.environ['no_proxy'] = 'localhost,127.0.0.1,::1'

# LLM å’ŒåµŒå…¥å‡½æ•°å®šä¹‰
async def ollama_llm_func(prompt, **kwargs):
    """Ollama LLM å‡½æ•°"""
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                "http://10.100.1.115:11434/api/generate",
                json={
                    "model": "gpt-oss:20b",
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "num_predict": 500,
                        "temperature": 0.7
                    }
                }
            )
            if response.status_code == 200:
                return response.json().get("response", "No response")
            else:
                return f"Error: {response.status_code}"
    except Exception as e:
        return f"LLM Error: {str(e)}"

async def ollama_embed_func(texts, **kwargs):
    """Ollama åµŒå…¥å‡½æ•° - ç¬¦åˆ RAG-Anything æ ‡å‡†"""
    if isinstance(texts, str):
        texts = [texts]
    
    # é™åˆ¶å¹¶å‘æ•°ï¼Œé¿å…æœåŠ¡å™¨è¿‡è½½
    semaphore = asyncio.Semaphore(5)  # æœ€å¤š5ä¸ªå¹¶å‘è¯·æ±‚
    
    async def get_embedding(client, text):
        async with semaphore:
            try:
                response = await client.post(
                    "http://10.100.1.115:11435/api/embeddings",
                    json={
                        "model": "dengcao/Qwen3-Embedding-8B:Q5_K_M",
                        "prompt": text
                    }
                )
                if response.status_code == 200:
                    embedding = response.json().get("embedding", [])
                    if embedding:
                        return embedding
                # å¦‚æœå¤±è´¥ï¼Œè¿”å›éšæœºå‘é‡ï¼ˆç¡®ä¿ç»´åº¦æ­£ç¡®ï¼‰
                return np.random.normal(0, 1, 3072).tolist()
            except Exception as e:
                logging.warning(f"å•ä¸ªåµŒå…¥è¯·æ±‚å¤±è´¥: {e}")
                return np.random.normal(0, 1, 3072).tolist()
    
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            # å¹¶å‘å¤„ç†æ‰€æœ‰æ–‡æœ¬
            tasks = [get_embedding(client, text) for text in texts]
            embeddings = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†å¼‚å¸¸ç»“æœ
            result_embeddings = []
            for emb in embeddings:
                if isinstance(emb, Exception):
                    result_embeddings.append(np.random.normal(0, 1, 3072).tolist())
                else:
                    result_embeddings.append(emb)
            
            return result_embeddings
            
    except Exception as e:
        logging.warning(f"åµŒå…¥å‡½æ•°å‡ºé”™: {e}ï¼Œä½¿ç”¨éšæœºåµŒå…¥")
        return [np.random.normal(0, 1, 3072).tolist() for _ in texts]

@define
class QdrantManager:
    """Qdrant å‘é‡æ•°æ®åº“ç®¡ç†å™¨ - ä¸ RAG-Anything é›†æˆ"""
    
    host: str = field(default="localhost")
    port: int = field(default=6333)
    timeout: int = field(default=60)
    prefer_grpc: bool = field(default=False)
    collection_name: str = field(default="rag_anything_kb")
    vector_size: int = field(default=3072)  # ä½¿ç”¨ RAG-Anything æ ‡å‡†åµŒå…¥ç»´åº¦
    client: QdrantClient = field(init=False)
    
    def __attrs_post_init__(self):
        """åˆå§‹åŒ– Qdrant å®¢æˆ·ç«¯"""
        self.client = QdrantClient(
            host=self.host,
            port=self.port,
            timeout=self.timeout,
            prefer_grpc=self.prefer_grpc
        )
        logging.info(f"ğŸ”Œ Qdrant å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ: {self.host}:{self.port}")
    
    def setup_collection(self) -> bool:
        """è®¾ç½® Qdrant é›†åˆ"""
        try:
            collections = self.client.get_collections()
            collection_exists = any(c.name == self.collection_name for c in collections.collections)
            
            if collection_exists:
                info = self.client.get_collection(self.collection_name)
                logging.info(f"âœ… ä½¿ç”¨ç°æœ‰é›†åˆ '{self.collection_name}' ({info.points_count} ä¸ªæ–‡æ¡£)")
                return True
            
            self.client.create_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(size=self.vector_size, distance=Distance.COSINE)
            )
            logging.info(f"âœ… åˆ›å»ºæ–°é›†åˆ '{self.collection_name}'")
            return True
            
        except Exception as e:
            logging.error(f"âŒ é›†åˆè®¾ç½®å¤±è´¥: {e}")
            return False
    
    def upsert_points(self, points: List[PointStruct], batch_size: int = 20) -> int:
        """æ‰¹é‡æ’å…¥/æ›´æ–°ç‚¹"""
        total_inserted = 0
        
        for i in range(0, len(points), batch_size):
            batch = points[i:i+batch_size]
            self.client.upsert(collection_name=self.collection_name, points=batch)
            total_inserted += len(batch)
            logging.info(f"ğŸ“¥ å·²æ’å…¥ {total_inserted}/{len(points)} ä¸ªæ–‡æ¡£å—")
        
        return total_inserted
    
    def search(self, query_vector: List[float], limit: int = 5) -> List[Dict]:
        """æœç´¢ç›¸ä¼¼å‘é‡"""
        try:
            results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                limit=limit,
                with_payload=True
            )
            
            return [{
                "score": result.score,
                "content": result.payload["content"],
                "file_path": result.payload["file_path"],
                "file_name": result.payload["file_name"],
                "chunk_index": result.payload.get("chunk_index", 0),
                "metadata": result.payload.get("metadata", {})
            } for result in results]
            
        except Exception as e:
            logging.error(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_collection_info(self) -> Dict[str, Any]:
        """è·å–é›†åˆä¿¡æ¯"""
        try:
            info = self.client.get_collection(self.collection_name)
            return {
                "points_count": info.points_count,
                "vector_size": info.config.params.vectors.size,
                "distance": info.config.params.vectors.distance,
                "collection_name": self.collection_name
            }
        except Exception as e:
            logging.error(f"âŒ è·å–é›†åˆä¿¡æ¯å¤±è´¥: {e}")
            return {}


@define
class LLMManager:
    """LLM æ¨¡å‹ç®¡ç†å™¨"""
    
    host: str = field(default="10.100.1.115:11434")
    model: str = field(default="gpt-oss:20b")
    base_url: str = field(init=False)
    default_options: Dict[str, Any] = field(factory=lambda: {
        "num_predict": 800,
        "temperature": 0.7
    })
    
    def __attrs_post_init__(self):
        """åˆå§‹åŒ– LLM é…ç½®"""
        self.base_url = f"http://{self.host}/api/generate"
        logging.info(f"ğŸ¤– LLM ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ: {self.host}, æ¨¡å‹: {self.model}")
    
    async def generate(self, prompt: str, stream: bool = False, **options) -> str:
        """ç”Ÿæˆæ–‡æœ¬"""
        merged_options = {**self.default_options, **options}
        
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": stream,
            "options": merged_options
        }
        
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(self.base_url, json=payload)
                if response.status_code == 200:
                    return response.json().get("response", "æœªè·å–åˆ°å“åº”")
                else:
                    return f"âŒ LLM é”™è¯¯ ({response.status_code})"
        except Exception as e:
            logging.error(f"âŒ è¿æ¥ LLM å¤±è´¥: {e}")
            return f"âŒ è¿æ¥ LLM å¤±è´¥: {e}"
    
    def create_rag_prompt(self, question: str, context: str) -> str:
        """åˆ›å»º RAG æç¤ºè¯ - ä½¿ç”¨ COSTAR æ¶æ„"""
        return f"""# Context (èƒŒæ™¯)
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†åº“é—®ç­”åŠ©æ‰‹ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„æŠ€æœ¯çŸ¥è¯†å’Œæ–‡æ¡£ç†è§£èƒ½åŠ›ã€‚ä½ æ­£åœ¨åŸºäºç”¨æˆ·æä¾›çš„çŸ¥è¯†åº“æ–‡æ¡£æ¥å›ç­”æŠ€æœ¯é—®é¢˜ã€‚å½“å‰ä½ é¢å‰æœ‰ç»è¿‡æ£€ç´¢ç­›é€‰çš„ç›¸å…³æ–‡æ¡£ç‰‡æ®µï¼Œéœ€è¦ä»ä¸­æå–å‡†ç¡®ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„å…·ä½“é—®é¢˜ã€‚

# Objective (ç›®æ ‡)
ä½ çš„ä¸»è¦ç›®æ ‡æ˜¯ï¼š
1. åŸºäºæä¾›çš„å‚è€ƒæ–‡æ¡£ï¼Œå‡†ç¡®å›ç­”ç”¨æˆ·çš„æŠ€æœ¯é—®é¢˜
2. æä¾›è¯¦ç»†ã€å®ç”¨çš„è§£å†³æ–¹æ¡ˆæˆ–è§£é‡Š
3. ç¡®ä¿ç­”æ¡ˆçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
4. å½“æ–‡æ¡£ä¿¡æ¯ä¸è¶³æ—¶ï¼Œè¯šå®è¯´æ˜é™åˆ¶

# Style (é£æ ¼)
é‡‡ç”¨ä¸“ä¸šè€Œå‹å¥½çš„æŠ€æœ¯å†™ä½œé£æ ¼ï¼š
- ä½¿ç”¨æ¸…æ™°çš„é€»è¾‘ç»“æ„
- æä¾›å…·ä½“çš„æ­¥éª¤æˆ–ç¤ºä¾‹
- å¼•ç”¨å…·ä½“çš„æ–‡æ¡£å†…å®¹ä½œä¸ºä¾æ®
- ä½¿ç”¨é€‚å½“çš„æŠ€æœ¯æœ¯è¯­ï¼Œä½†ä¿æŒæ˜“æ‡‚

# Tone (è¯­è°ƒ)
ä¿æŒä¸“ä¸šã€è€å¿ƒã€æœ‰å¸®åŠ©çš„è¯­è°ƒï¼š
- ä¸“ä¸šæƒå¨ä½†ä¸åˆ»æ¿
- å‹å–„è€å¿ƒï¼Œæ˜“äºç†è§£
- è‡ªä¿¡åœ°æä¾›ä¿¡æ¯ï¼Œä½†æ‰¿è®¤ä¸ç¡®å®šæ€§
- ç§¯æä¸»åŠ¨åœ°æä¾›é¢å¤–æœ‰ä»·å€¼çš„ä¿¡æ¯

# Audience (å—ä¼—)
ç›®æ ‡å—ä¼—æ˜¯å¯»æ±‚æŠ€æœ¯å¸®åŠ©çš„ç”¨æˆ·ï¼Œä»–ä»¬å¯èƒ½ï¼š
- å…·æœ‰ä¸€å®šçš„æŠ€æœ¯èƒŒæ™¯
- éœ€è¦å…·ä½“çš„å®æ–½æŒ‡å¯¼
- å¸Œæœ›è·å¾—å¯é çš„å‚è€ƒä¾æ®
- é‡è§†å‡†ç¡®æ€§å’Œå®ç”¨æ€§

# Response (å“åº”æ ¼å¼)
è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç»„ç»‡ä½ çš„å›ç­”ï¼š

## ç›´æ¥å›ç­”
[åŸºäºæ–‡æ¡£å†…å®¹çš„æ ¸å¿ƒç­”æ¡ˆ]

## è¯¦ç»†è¯´æ˜
[æä¾›æ›´è¯¦ç»†çš„è§£é‡Šå’Œæ­¥éª¤]

## æ–‡æ¡£ä¾æ®
[å¼•ç”¨å…·ä½“çš„æ–‡æ¡£ç‰‡æ®µå’Œæ¥æº]

## è¡¥å……å»ºè®®
[å¦‚æœæœ‰ç›¸å…³çš„é¢å¤–å»ºè®®æˆ–æ³¨æ„äº‹é¡¹]

## ä¿¡æ¯å®Œæ•´æ€§è¯´æ˜
[è¯´æ˜å½“å‰æ–‡æ¡£æ˜¯å¦åŒ…å«å®Œæ•´ä¿¡æ¯ï¼Œæˆ–è€…è¿˜éœ€è¦ä»€ä¹ˆé¢å¤–ä¿¡æ¯]

---

## å‚è€ƒæ–‡æ¡£å†…å®¹:
{context}

## ç”¨æˆ·é—®é¢˜:
{question}

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¦æ±‚å›ç­”ï¼š"""


@define
class RAGAnythingProcessor:
    """RAG-Anything æ–‡æ¡£å¤„ç†å™¨"""
    
    rag_engine: RAGAnything = field(init=False)
    config: RAGAnythingConfig = field(init=False)
    working_dir: Path = field(factory=lambda: Path("./rag_storage"))
    
    def __attrs_post_init__(self):
        """åˆå§‹åŒ– RAG-Anything å¼•æ“"""
        try:
            self.working_dir.mkdir(exist_ok=True)
            
            # é…ç½® RAG-Anything - ä¼˜åŒ–è½»é‡çº§æ–‡ä»¶å¤„ç†
            self.config = RAGAnythingConfig(
                working_dir=str(self.working_dir),
                parse_method="text",  # å¯¹äºMD/TXTä½¿ç”¨æ–‡æœ¬è§£æè€ŒéMinerU
                parser_output_dir=str(self.working_dir / "output"),
                parser="text",  # ä½¿ç”¨æ–‡æœ¬è§£æå™¨è€Œémineru
                display_content_stats=True,
                enable_image_processing=False,  # MDæ–‡ä»¶ä¸éœ€è¦å›¾ç‰‡å¤„ç†
                enable_table_processing=False,  # ç®€åŒ–è¡¨æ ¼å¤„ç†
                enable_equation_processing=False,  # ç®€åŒ–å…¬å¼å¤„ç†
                max_concurrent_files=2,  # å‡å°‘å¹¶å‘æ•°
                recursive_folder_processing=True
            )
            
            # åˆå§‹åŒ–åµŒå…¥å‡½æ•° - ä½¿ç”¨æ­£ç¡®çš„ EmbeddingFunc æ¥å£
            embedding_func = EmbeddingFunc(
                embedding_dim=3072,
                max_token_size=8192,
                func=ollama_embed_func
            )
            
            # åˆå§‹åŒ– RAG-Anything å¼•æ“ï¼ˆé…ç½® LLM å’ŒåµŒå…¥å‡½æ•°ï¼‰
            self.rag_engine = RAGAnything(
                config=self.config,
                llm_model_func=ollama_llm_func,
                embedding_func=embedding_func
            )
            logging.info("ğŸš€ RAG-Anything å¼•æ“åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logging.error(f"âŒ RAG-Anything åˆå§‹åŒ–å¤±è´¥: {e}")
            # å›é€€åˆ°åŸºç¡€å¤„ç†
            self.rag_engine = None
    
    async def process_documents(self, documents_path: Union[str, Path]) -> Dict[str, Any]:
        """æ™ºèƒ½å¤„ç†æ–‡æ¡£é›†åˆ - é’ˆå¯¹ä¸åŒæ–‡ä»¶ç±»å‹ä½¿ç”¨ä¸åŒç­–ç•¥"""
        if not self.rag_engine:
            logging.error("âŒ RAG-Anything å¼•æ“æœªåˆå§‹åŒ–")
            return {'success': False, 'error': 'RAG-Anything å¼•æ“æœªåˆå§‹åŒ–'}
        
        try:
            documents_path = Path(documents_path)
            logging.info(f"ğŸ“š å¼€å§‹æ™ºèƒ½å¤„ç†æ–‡æ¡£ç›®å½•: {documents_path}")
            
            # åˆ†ç±»æ–‡ä»¶
            lightweight_files = []  # MD, TXT
            heavyweight_files = []  # PDF, DOCX, PPTXç­‰
            
            for ext in [".md", ".txt"]:
                for file_path in documents_path.rglob(f"*{ext}"):
                    if file_path.is_file():
                        lightweight_files.append(file_path)
            
            for ext in [".pdf", ".docx", ".pptx", ".xlsx", ".xls"]:
                for file_path in documents_path.rglob(f"*{ext}"):
                    if file_path.is_file():
                        heavyweight_files.append(file_path)
            
            logging.info(f"ğŸ“Š æ–‡ä»¶åˆ†ç±»: è½»é‡çº§ {len(lightweight_files)} ä¸ª, é‡é‡çº§ {len(heavyweight_files)} ä¸ª")
            
            total_processed = 0
            
            # 1. å¿«é€Ÿå¤„ç†è½»é‡çº§æ–‡ä»¶ (MD/TXT) - ç›´æ¥æ–‡æœ¬æ’å…¥
            if lightweight_files:
                logging.info(f"âš¡ å¼€å§‹å¿«é€Ÿå¤„ç† {len(lightweight_files)} ä¸ªè½»é‡çº§æ–‡ä»¶...")
                for file_path in lightweight_files:
                    try:
                        await self._process_text_file_directly(file_path)
                        total_processed += 1
                        if total_processed % 10 == 0:
                            logging.info(f"âš¡ å·²å¤„ç† {total_processed} ä¸ªè½»é‡çº§æ–‡ä»¶")
                    except Exception as e:
                        logging.warning(f"âš ï¸ å¤„ç†å¤±è´¥ {file_path.name}: {e}")
            
            # 2. é‡é‡çº§æ–‡ä»¶ä½¿ç”¨ MinerU (å¦‚æœæœ‰çš„è¯)
            if heavyweight_files:
                logging.info(f"ğŸ”§ å¼€å§‹å¤„ç† {len(heavyweight_files)} ä¸ªé‡é‡çº§æ–‡ä»¶...")
                # è¿™é‡Œå¯ä»¥ä½¿ç”¨æ ‡å‡†APIå¤„ç†é‡é‡çº§æ–‡ä»¶
                # ä½†ç›®å‰å…ˆè·³è¿‡ï¼Œä¸“æ³¨äºè½»é‡çº§æ–‡ä»¶çš„ä¼˜åŒ–
                logging.info("âš ï¸ é‡é‡çº§æ–‡ä»¶å¤„ç†å·²è·³è¿‡ï¼Œå¦‚éœ€å¤„ç†è¯·ä¿®æ”¹é…ç½®")
            
            logging.info(f"ğŸ‰ å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {total_processed} ä¸ªæ–‡ä»¶")
            
            return {
                'success': True,
                'processed_count': total_processed,
                'lightweight_count': len(lightweight_files),
                'heavyweight_count': len(heavyweight_files),
                'metadata': {'processing_method': 'intelligent_mixed'}
            }
            
        except Exception as e:
            logging.error(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    async def _process_text_file_directly(self, file_path: Path) -> bool:
        """ç›´æ¥å¤„ç†æ–‡æœ¬æ–‡ä»¶ï¼Œé¿å…è½¬æ¢æˆPDF"""
        try:
            # ç›´æ¥è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ç®€å•åˆ†å—
            chunk_size = 1000
            chunks = []
            for i in range(0, len(content), chunk_size):
                chunk_text = content[i:i + chunk_size].strip()
                if chunk_text:
                    chunks.append({
                        "type": "text",
                        "text": chunk_text,
                        "page_idx": i // chunk_size,
                        "file_path": str(file_path),
                        "chunk_index": i // chunk_size
                    })
            
            if chunks:
                # ç›´æ¥ä½¿ç”¨ RAG-Anything çš„æ’å…¥æ–¹æ³•
                await self.rag_engine.insert_content_list(
                    content_list=chunks,
                    file_path=str(file_path),
                    doc_id=f"direct_{file_path.stem}"
                )
                logging.info(f"âœ… ç›´æ¥å¤„ç†æ–‡ä»¶: {file_path.name} ({len(chunks)} ä¸ªå—)")
                return True
            
            return False
            
        except Exception as e:
            logging.error(f"âŒ ç›´æ¥å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return False
    
    async def process_single_file(self, file_path: Union[str, Path]) -> Dict[str, Any]:
        """ä½¿ç”¨ RAG-Anything æ ‡å‡† API å¤„ç†å•ä¸ªæ–‡ä»¶"""
        if not self.rag_engine:
            logging.error("âŒ RAG-Anything å¼•æ“æœªåˆå§‹åŒ–")
            return {'success': False, 'error': 'RAG-Anything å¼•æ“æœªåˆå§‹åŒ–'}
        
        try:
            file_path = Path(file_path)
            logging.info(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {file_path}")
            
            # ä½¿ç”¨ RAG-Anything æ ‡å‡† API å¤„ç†å•ä¸ªæ–‡ä»¶
            result = await self.rag_engine.process_document_complete(
                file_path=str(file_path),
                output_dir=str(self.working_dir / "output")
            )
            
            return {
                'success': True,
                'result': result,
                'metadata': {'processing_method': 'rag_anything_standard_api', 'file_type': file_path.suffix.lower()}
            }
            
        except Exception as e:
            logging.error(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {'success': False, 'error': str(e)}
    
    def get_supported_formats(self) -> List[str]:
        """è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
        return [
            '.pdf', '.docx', '.doc', '.pptx', '.ppt', 
            '.xlsx', '.xls', '.csv',
            '.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.gif', '.webp',
            '.md', '.txt', '.rtf',
            '.html', '.htm'
        ]


@define
class RAGAnythingQueryManager:
    """RAG-Anything æŸ¥è¯¢ç®¡ç†å™¨ - ä½¿ç”¨æ ‡å‡†API"""
    
    rag_engine: RAGAnything = field()
    working_dir: Path = field(factory=lambda: Path("./rag_storage"))
    
    def __attrs_post_init__(self):
        """åˆå§‹åŒ–æŸ¥è¯¢ç®¡ç†å™¨"""
        self.working_dir.mkdir(exist_ok=True)
        logging.info("ğŸ” RAG-Anything æŸ¥è¯¢ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def validate_rag_ready(self) -> bool:
        """éªŒè¯ RAG ç³»ç»Ÿæ˜¯å¦å‡†å¤‡å°±ç»ª"""
        if not self.rag_engine:
            logging.error("âŒ RAG å¼•æ“æœªåˆå§‹åŒ–")
            return False
        return True
    
    async def query_text(self, query: str, mode: str = "hybrid") -> str:
        """çº¯æ–‡æœ¬æŸ¥è¯¢ - ä½¿ç”¨ RAG-Anything æ ‡å‡† API"""
        if not self.validate_rag_ready():
            return "âŒ RAG ç³»ç»Ÿæœªå°±ç»ªï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢"
        
        try:
            # ä½¿ç”¨ RAG-Anything æä¾›çš„æ ‡å‡†æŸ¥è¯¢æ–¹æ³•
            result = await self.rag_engine.aquery(query, mode=mode)
            return result
            
        except Exception as e:
            logging.error(f"âŒ æ–‡æœ¬æŸ¥è¯¢å¤±è´¥: {e}")
            return f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"
    
    async def query_multimodal(self, query: str, multimodal_content: List[Dict[str, Any]], mode: str = "hybrid") -> str:
        """å¤šæ¨¡æ€æŸ¥è¯¢ - ä½¿ç”¨ RAG-Anything æ ‡å‡† API"""
        if not self.validate_rag_ready():
            return "âŒ RAG ç³»ç»Ÿæœªå°±ç»ªï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢"
        
        try:
            # ä½¿ç”¨ RAG-Anything æä¾›çš„å¤šæ¨¡æ€æŸ¥è¯¢æ–¹æ³•
            result = await self.rag_engine.aquery_with_multimodal(
                query=query,
                multimodal_content=multimodal_content,
                mode=mode
            )
            return result
            
        except Exception as e:
            logging.error(f"âŒ å¤šæ¨¡æ€æŸ¥è¯¢å¤±è´¥: {e}")
            return f"å¤šæ¨¡æ€æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"
    
    def query_text_sync(self, query: str, mode: str = "hybrid") -> str:
        """åŒæ­¥ç‰ˆæœ¬çš„æ–‡æœ¬æŸ¥è¯¢"""
        if not self.validate_rag_ready():
            return "âŒ RAG ç³»ç»Ÿæœªå°±ç»ªï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢"
        
        try:
            # ä½¿ç”¨ RAG-Anything æä¾›çš„åŒæ­¥æŸ¥è¯¢æ–¹æ³•
            result = self.rag_engine.query(query, mode=mode)
            return result
            
        except Exception as e:
            logging.error(f"âŒ åŒæ­¥æ–‡æœ¬æŸ¥è¯¢å¤±è´¥: {e}")
            return f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"


@define
class RAGAnythingSystem:
    """RAG-Anything ç³»ç»Ÿä¸»ç±»"""
    
    knowledge_base_path: Union[str, Path] = field(converter=Path)
    collection_name: str = field(default="rag_anything_kb")
    qdrant_host: str = field(default="localhost")
    qdrant_port: int = field(default=6333)
    llm_host: str = field(default="10.100.1.115:11434")
    llm_model: str = field(default="gpt-oss:20b")
    vector_size: int = field(default=3072)
    
    # ç»„ä»¶
    qdrant_manager: QdrantManager = field(init=False)
    llm_manager: LLMManager = field(init=False)
    doc_processor: RAGAnythingProcessor = field(init=False)
    query_manager: RAGAnythingQueryManager = field(init=False)
    
    def __attrs_post_init__(self):
        """åˆå§‹åŒ– RAG-Anything ç³»ç»Ÿç»„ä»¶"""
        # åˆå§‹åŒ– Qdrant ç®¡ç†å™¨
        self.qdrant_manager = QdrantManager(
            host=self.qdrant_host,
            port=self.qdrant_port,
            collection_name=self.collection_name,
            vector_size=self.vector_size
        )
        
        # åˆå§‹åŒ– LLM ç®¡ç†å™¨
        self.llm_manager = LLMManager(
            host=self.llm_host,
            model=self.llm_model
        )
        
        # åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨
        self.doc_processor = RAGAnythingProcessor()
        
        # ç­‰å¾…æ–‡æ¡£å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆåå†åˆå§‹åŒ–æŸ¥è¯¢ç®¡ç†å™¨
        if self.doc_processor.rag_engine:
            self.query_manager = RAGAnythingQueryManager(
                rag_engine=self.doc_processor.rag_engine
            )
        else:
            logging.error("âŒ æ–‡æ¡£å¤„ç†å™¨çš„ RAG å¼•æ“æœªåˆå§‹åŒ–ï¼ŒæŸ¥è¯¢åŠŸèƒ½ä¸å¯ç”¨")
            self.query_manager = None
        
        logging.info("ğŸš€ RAG-Anything ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def setup(self) -> bool:
        """è®¾ç½® RAG ç³»ç»Ÿ"""
        return self.qdrant_manager.setup_collection()
    
    async def index_documents(self, force_rebuild: bool = False) -> bool:
        """ä½¿ç”¨ RAG-Anything ç´¢å¼•æ–‡æ¡£"""
        logging.info("ğŸ“š å¼€å§‹ä½¿ç”¨ RAG-Anything ç´¢å¼•æ–‡æ¡£...")
        
        try:
            # ä½¿ç”¨ RAG-Anything å¤„ç†æ–‡æ¡£
            processed_data = await self.doc_processor.process_documents(self.knowledge_base_path)
            
            if not processed_data['success']:
                logging.error(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: {processed_data.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return False
            
            logging.info("ğŸ‰ RAG-Anything ç´¢å¼•å®Œæˆï¼")
            return True
            
        except Exception as e:
            logging.error(f"âŒ ç´¢å¼•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    def batch_update_documents(self, file_paths: List[Union[str, Path]]) -> bool:
        """æ‰¹é‡æ›´æ–°æ–‡æ¡£"""
        logging.info(f"ğŸ“ å¼€å§‹æ‰¹é‡æ›´æ–° {len(file_paths)} ä¸ªæ–‡ä»¶")
        
        success_count = 0
        for file_path in file_paths:
            try:
                file_path = Path(file_path)
                if self._update_single_document(file_path):
                    success_count += 1
            except Exception as e:
                logging.error(f"âŒ æ›´æ–°æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        logging.info(f"âœ… æ‰¹é‡æ›´æ–°å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{len(file_paths)}")
        return success_count > 0
    
    def _update_single_document(self, file_path: Path) -> bool:
        """æ›´æ–°å•ä¸ªæ–‡æ¡£"""
        # è¿™é‡Œåº”è¯¥å®ç°å¢é‡æ›´æ–°é€»è¾‘
        # ç›®å‰ç®€åŒ–ä¸ºé‡æ–°å¤„ç†æ•´ä¸ªæ–‡ä»¶
        logging.info(f"ğŸ“„ æ›´æ–°æ–‡æ¡£: {file_path}")
        return True
    
    async def answer_question(self, question: str, mode: str = "hybrid", multimodal_content: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ä½¿ç”¨ RAG-Anything æ ‡å‡† API å›ç­”é—®é¢˜"""
        logging.info(f"ğŸ¤” é—®é¢˜: {question}")
        
        try:
            if not self.query_manager:
                return {
                    "question": question,
                    "answer": "âŒ æŸ¥è¯¢ç³»ç»Ÿæœªæ­£ç¡®åˆå§‹åŒ–",
                    "mode": mode,
                    "status": "error"
                }
            
            logging.info(f"ğŸ” ä½¿ç”¨ RAG-Anything æŸ¥è¯¢ (æ¨¡å¼: {mode})...")
            
            # æ ¹æ®æ˜¯å¦æœ‰å¤šæ¨¡æ€å†…å®¹é€‰æ‹©æŸ¥è¯¢æ–¹æ³•
            if multimodal_content:
                answer = await self.query_manager.query_multimodal(
                    query=question,
                    multimodal_content=multimodal_content,
                    mode=mode
                )
                query_type = "multimodal"
            else:
                answer = await self.query_manager.query_text(
                    query=question,
                    mode=mode
                )
                query_type = "text"
            
            return {
                "question": question,
                "answer": answer,
                "mode": mode,
                "query_type": query_type,
                "multimodal_content": multimodal_content if multimodal_content else None,
                "status": "success"
            }
            
        except Exception as e:
            logging.error(f"âŒ é—®ç­”è¿‡ç¨‹å‡ºé”™: {e}")
            return {
                "question": question,
                "answer": f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}",
                "mode": mode,
                "status": "error"
            }
    
    async def answer_question_with_table(self, question: str, table_data: str, table_caption: str = "", mode: str = "hybrid") -> Dict[str, Any]:
        """å¸¦è¡¨æ ¼æ•°æ®çš„æŸ¥è¯¢"""
        multimodal_content = [{
            "type": "table",
            "table_data": table_data,
            "table_caption": table_caption
        }]
        return await self.answer_question(question, mode, multimodal_content)
    
    async def answer_question_with_equation(self, question: str, latex: str, equation_caption: str = "", mode: str = "hybrid") -> Dict[str, Any]:
        """å¸¦å…¬å¼çš„æŸ¥è¯¢"""
        multimodal_content = [{
            "type": "equation",
            "latex": latex,
            "equation_caption": equation_caption
        }]
        return await self.answer_question(question, mode, multimodal_content)
    
    def print_rag_result(self, result: Dict[str, Any]):
        """æ‰“å° RAG-Anything ç»“æœ"""
        print("=" * 80)
        print("ğŸ¯ RAG-Anything é—®ç­”ç»“æœ")
        print("=" * 80)
        
        print(f"â“ é—®é¢˜: {result['question']}")
        print(f"ğŸ” æŸ¥è¯¢æ¨¡å¼: {result.get('mode', 'hybrid')}")
        print(f"ğŸ“ æŸ¥è¯¢ç±»å‹: {result.get('query_type', 'text')}")
        
        if result.get('multimodal_content'):
            print(f"ğŸ¨ å¤šæ¨¡æ€å†…å®¹: {len(result['multimodal_content'])} é¡¹")
            for i, content in enumerate(result['multimodal_content'], 1):
                content_type = content.get('type', 'unknown')
                icon = {'table': 'ğŸ“Š', 'equation': 'ğŸ§®', 'image': 'ğŸ–¼ï¸'}.get(content_type, 'ğŸ“„')
                print(f"   {i}. {icon} {content_type.upper()}")
                if content.get('table_caption'):
                    print(f"      æ ‡é¢˜: {content['table_caption']}")
                elif content.get('equation_caption'):
                    print(f"      è¯´æ˜: {content['equation_caption']}")
        
        print(f"\nğŸ¤– å›ç­”:\n{result['answer']}")
        print(f"\nğŸ“Š çŠ¶æ€: {result.get('status', 'unknown')}")
        print("=" * 80)
    
    async def interactive_session(self):
        """äº¤äº’å¼é—®ç­”ä¼šè¯"""
        print("\nğŸ‰ æ¬¢è¿ä½¿ç”¨ RAG-Anything äº¤äº’å¼é—®ç­”ç³»ç»Ÿï¼")
        print("ğŸ’¡ æç¤º:")
        print("   - ç›´æ¥è¾“å…¥é—®é¢˜è¿›è¡ŒæŸ¥è¯¢")
        print("   - è¾“å…¥ 'mode:hybrid ä½ çš„é—®é¢˜' æŒ‡å®šæŸ¥è¯¢æ¨¡å¼ (hybrid/local/global/naive)")
        print("   - è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("   - è¾“å…¥ 'stats' æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
        print("   - è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
        print("   - è¾“å…¥ 'reindex' é‡æ–°ç´¢å¼•æ–‡æ¡£")
        
        while True:
            try:
                user_input = input("\nğŸ—£ï¸  è¯·è¾“å…¥é—®é¢˜: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ å†è§ï¼æ„Ÿè°¢ä½¿ç”¨ RAG é—®ç­”ç³»ç»Ÿï¼")
                    break
                
                if user_input.lower() == 'stats':
                    try:
                        print(f"ğŸ“Š RAG-Anything ç³»ç»ŸçŠ¶æ€:")
                        print(f"   - ç³»ç»Ÿç±»å‹: RAG-Anything å¤šæ¨¡æ€ç³»ç»Ÿ")
                        if self.doc_processor.rag_engine:
                            print(f"   - RAG å¼•æ“çŠ¶æ€: âœ… å·²åˆå§‹åŒ–")
                        else:
                            print(f"   - RAG å¼•æ“çŠ¶æ€: âŒ æœªåˆå§‹åŒ–")
                        
                        print(f"   - å·¥ä½œç›®å½•: {self.doc_processor.working_dir}")
                        print(f"   - æ”¯æŒæ ¼å¼: {self.doc_processor.get_supported_formats()}")
                        print(f"   - æ”¯æŒæŸ¥è¯¢æ¨¡å¼: hybrid, local, global, naive")
                    except Exception as e:
                        logging.error(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {e}")
                    continue
                
                if user_input.lower() == 'help':
                    print("ğŸ“– RAG-Anything ç³»ç»Ÿå¸®åŠ©:")
                    print("   - ğŸ¯ å¤šæ¨¡æ€æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼ŒåŸºäº RAG-Anything æ¡†æ¶")
                    print("   - ğŸ“„ æ”¯æŒæ–‡æ¡£: PDF, DOCX, PPTX, XLSX, MD, TXT")
                    print("   - ğŸ–¼ï¸ æ”¯æŒå›¾ç‰‡: PNG, JPG, JPEG, BMP, TIFF, GIF, WEBP")
                    print("   - ğŸ“Š æ”¯æŒè¡¨æ ¼å’Œå…¬å¼çš„æ™ºèƒ½ç†è§£")
                    print("   - ğŸ” æŸ¥è¯¢æ¨¡å¼:")
                    print("     â€¢ hybrid: æ··åˆæ¨¡å¼ (æ¨è)")
                    print("     â€¢ local: å±€éƒ¨æœç´¢")
                    print("     â€¢ global: å…¨å±€æœç´¢")
                    print("     â€¢ naive: æœ´ç´ æœç´¢")
                    print("   - ğŸ’¡ ç¤ºä¾‹æŸ¥è¯¢:")
                    print("     â€¢ ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ ")
                    print("     â€¢ mode:local ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ?")
                    print("     â€¢ mode:global æ€»ç»“æ‰€æœ‰æ–‡æ¡£çš„è¦ç‚¹")
                    continue
                
                if user_input.lower() == 'reindex':
                    print("ğŸ”„ å¼€å§‹é‡æ–°ç´¢å¼•æ–‡æ¡£...")
                    success = await self.index_documents(force_rebuild=True)
                    if success:
                        print("âœ… é‡æ–°ç´¢å¼•å®Œæˆ")
                    else:
                        print("âŒ é‡æ–°ç´¢å¼•å¤±è´¥")
                    continue
                
                # è§£ææŸ¥è¯¢æ¨¡å¼
                mode = "hybrid"  # é»˜è®¤æ¨¡å¼
                question = user_input
                
                if user_input.startswith("mode:"):
                    parts = user_input.split(" ", 1)
                    if len(parts) == 2:
                        mode_part = parts[0].replace("mode:", "")
                        if mode_part in ["hybrid", "local", "global", "naive"]:
                            mode = mode_part
                            question = parts[1]
                        else:
                            print(f"âš ï¸ æœªçŸ¥æŸ¥è¯¢æ¨¡å¼: {mode_part}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼ hybrid")
                            question = user_input
                
                # å¤„ç†é—®é¢˜
                result = await self.answer_question(question, mode=mode)
                self.print_rag_result(result)
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç¨‹åºè¢«ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except Exception as e:
                logging.error(f"âŒ å¤„ç†å‡ºé”™: {e}")
                print(f"âŒ å¤„ç†å‡ºé”™: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('rag_anything_system.log', encoding='utf-8')
        ]
    )
    
    print("ğŸš€ RAG-Anything å¤šæ¨¡æ€æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    print("æ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ã€è¡¨æ ¼ã€å…¬å¼ç­‰å¤šç§å†…å®¹ç±»å‹")
    print("=" * 60)
    
    # é…ç½®
    KNOWLEDGE_BASE_PATH = "/Users/chenzi/chenzi/project/github/chenzi-knowledge-library"

    try:
        # åˆå§‹åŒ– RAG-Anything ç³»ç»Ÿ
        rag = RAGAnythingSystem(
            knowledge_base_path=KNOWLEDGE_BASE_PATH,
            collection_name="rag_anything_kb_v1",
            vector_size=384
        )
        
        # è®¾ç½®é›†åˆ
        if not rag.setup():
            logging.error("âŒ æ— æ³•è®¾ç½® Qdrant é›†åˆ")
            return
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç´¢å¼•ï¼ˆå¯¹äº RAG-Anythingï¼Œæˆ‘ä»¬æ€»æ˜¯å°è¯•å¤„ç†æ–‡æ¡£ï¼‰
        logging.info("ğŸ“š å¼€å§‹ä½¿ç”¨ RAG-Anything ç´¢å¼•æ–‡æ¡£...")
        success = await rag.index_documents()
        if not success:
            logging.warning("âš ï¸ ç´¢å¼•å¤±è´¥ï¼Œä½†ç³»ç»Ÿä»å¯èƒ½å·¥ä½œï¼ˆå¦‚æœä¹‹å‰å·²æœ‰æ•°æ®ï¼‰")
        
        # å¼€å§‹äº¤äº’å¼ä¼šè¯
        await rag.interactive_session()
        
    except Exception as e:
        logging.error(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        print(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main())