#!/usr/bin/env python3
"""
RAG ç³»ç»Ÿæ¼”ç¤ºç‰ˆæœ¬
å±•ç¤ºå®Œæ•´çš„ RAG é—®ç­”æµç¨‹
"""

import asyncio
import os
import json
import re
from pathlib import Path
from typing import List, Dict, Any
from qdrant_client import QdrantClient
import httpx
from datetime import datetime

# é¿å…ä»£ç†é—®é¢˜
os.environ['NO_PROXY'] = 'localhost,127.0.0.1,::1'
os.environ['no_proxy'] = 'localhost,127.0.0.1,::1'

class RAGDemo:
    """RAG æ¼”ç¤ºç³»ç»Ÿ"""
    
    def __init__(
        self,
        collection_name: str = "knowledge_base",
        ollama_host: str = "10.100.1.115:11434",
        ollama_model: str = "gpt-oss:20b"
    ):
        self.collection_name = collection_name
        self.ollama_host = ollama_host
        self.ollama_model = ollama_model
        self.ollama_url = f"http://{ollama_host}/api/generate"
        
        # Qdrant å®¢æˆ·ç«¯
        self.client = QdrantClient(
            host="localhost", 
            port=6333,
            timeout=60,
            prefer_grpc=False
        )
        
        # åŠ è½½è¯æ±‡è¡¨
        self.vocabulary = self.load_vocabulary()
        self.vocab_size = 1000
        
        print("ğŸ¯ RAG æ¼”ç¤ºç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def load_vocabulary(self) -> Dict[str, int]:
        """åŠ è½½è¯æ±‡è¡¨"""
        vocab_file = Path("./rag_storage/vocabulary.json")
        if vocab_file.exists():
            with open(vocab_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def text_to_vector(self, text: str) -> List[float]:
        """æ–‡æœ¬è½¬å‘é‡"""
        if not self.vocabulary:
            return [0.0] * self.vocab_size
        
        vector = [0.0] * len(self.vocabulary)
        words = re.findall(r'\w+', text.lower())
        
        for word in words:
            if word in self.vocabulary:
                vector[self.vocabulary[word]] += 1.0
        
        total = sum(vector)
        if total > 0:
            vector = [v / total for v in vector]
        
        while len(vector) < self.vocab_size:
            vector.append(0.0)
        
        return vector[:self.vocab_size]
    
    def search_documents(self, query: str, limit: int = 5) -> List[Dict]:
        """æœç´¢æ–‡æ¡£"""
        try:
            query_vector = self.text_to_vector(query)
            results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                limit=limit,
                with_payload=True
            )
            
            return [{
                "score": result.score,
                "content": result.payload["content"],
                "file_path": result.payload["file_path"],
                "file_name": result.payload["file_name"]
            } for result in results]
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    async def query_ollama(self, prompt: str) -> str:
        """æŸ¥è¯¢ Ollama"""
        payload = {
            "model": self.ollama_model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "num_predict": 600,
                "temperature": 0.7
            }
        }
        
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(self.ollama_url, json=payload)
                if response.status_code == 200:
                    return response.json().get("response", "æœªè·å–åˆ°å“åº”")
                else:
                    return f"âŒ Ollama é”™è¯¯ ({response.status_code})"
        except Exception as e:
            return f"âŒ è¿æ¥ Ollama å¤±è´¥: {e}"
    
    async def demo_rag_process(self, question: str):
        """æ¼”ç¤ºå®Œæ•´çš„ RAG å¤„ç†æµç¨‹"""
        print("=" * 80)
        print("ğŸ¯ RAG é—®ç­”æ¼”ç¤º")
        print("=" * 80)
        print(f"â“ é—®é¢˜: {question}")
        print()
        
        # æ­¥éª¤ 1: æ–‡æ¡£æœç´¢
        print("ğŸ” æ­¥éª¤ 1: æ–‡æ¡£å‘é‡æœç´¢")
        print("-" * 40)
        search_results = self.search_documents(question, limit=5)
        
        if not search_results:
            print("   âŒ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
            return
        
        # è¿‡æ»¤ç»“æœ
        filtered_results = [r for r in search_results if r['score'] > 0.05]
        if not filtered_results:
            filtered_results = search_results[:3]
        
        print(f"   âœ… æ‰¾åˆ° {len(filtered_results)} ä¸ªç›¸å…³æ–‡æ¡£:")
        for i, result in enumerate(filtered_results, 1):
            print(f"   {i}. {result['file_name']} (ç›¸ä¼¼åº¦: {result['score']:.3f})")
            print(f"      é¢„è§ˆ: {result['content'][:60]}...")
        
        # æ­¥éª¤ 2: æ„å»ºä¸Šä¸‹æ–‡
        print(f"\nğŸ”§ æ­¥éª¤ 2: æ„å»º RAG ä¸Šä¸‹æ–‡")
        print("-" * 40)
        
        context_parts = []
        for i, result in enumerate(filtered_results, 1):
            context_parts.append(f"ã€å‚è€ƒæ–‡æ¡£{i}ã€‘")
            context_parts.append(f"æ–‡ä»¶: {result['file_name']}")
            context_parts.append(f"å†…å®¹: {result['content']}")
            context_parts.append("---")
        
        context = '\n'.join(context_parts)
        print(f"   ğŸ“ ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
        print(f"   ğŸ“‹ åŒ…å« {len(filtered_results)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
        
        # æ˜¾ç¤ºä¸Šä¸‹æ–‡é¢„è§ˆ
        context_preview = context[:300] + "..." if len(context) > 300 else context
        print(f"   ğŸ” ä¸Šä¸‹æ–‡é¢„è§ˆ:\n{context_preview}")
        
        # æ­¥éª¤ 3: æ„å»ºæç¤ºè¯
        print(f"\nğŸ“ æ­¥éª¤ 3: æ„å»º AI æç¤ºè¯")
        print("-" * 40)
        
        rag_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åŠ©æ‰‹ï¼Œè¯·åŸºäºæä¾›çš„çŸ¥è¯†åº“æ–‡æ¡£å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

å›ç­”è¦æ±‚:
1. ä»…åŸºäºæä¾›çš„å‚è€ƒæ–‡æ¡£å†…å®¹å›ç­”
2. å›ç­”è¦å‡†ç¡®ã€è¯¦ç»†ã€æ˜“æ‡‚
3. å¯ä»¥å¼•ç”¨å…·ä½“æ–‡æ¡£å†…å®¹
4. å¦‚æœæ–‡æ¡£ä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯´æ˜
5. ç”¨ä¸­æ–‡å›ç­”

å‚è€ƒæ–‡æ¡£:
{context}

ç”¨æˆ·é—®é¢˜: {question}

è¯·å›ç­”:"""
        
        print(f"   ğŸ’¬ æç¤ºè¯é•¿åº¦: {len(rag_prompt)} å­—ç¬¦")
        print(f"   ğŸ¯ åŒ…å«å®Œæ•´çš„ä¸Šä¸‹æ–‡å’ŒæŒ‡ä»¤")
        
        # æ­¥éª¤ 4: AI ç”Ÿæˆå›ç­”
        print(f"\nğŸ¤– æ­¥éª¤ 4: AI æ¨¡å‹ç”Ÿæˆå›ç­”")
        print("-" * 40)
        
        print("   ğŸ”„ æ­£åœ¨è°ƒç”¨ Ollama æ¨¡å‹...")
        answer = await self.query_ollama(rag_prompt)
        
        print(f"   âœ… å›ç­”ç”Ÿæˆå®Œæˆ")
        print(f"   ğŸ“ å›ç­”é•¿åº¦: {len(answer)} å­—ç¬¦")
        
        # æ­¥éª¤ 5: å±•ç¤ºæœ€ç»ˆç»“æœ
        print(f"\nğŸ‰ æ­¥éª¤ 5: æœ€ç»ˆ RAG ç»“æœ")
        print("-" * 40)
        
        print(f"ğŸ¤– AI å›ç­”:")
        print(f"{answer}")
        
        print(f"\nğŸ“š å‚è€ƒæ¥æº:")
        for i, result in enumerate(filtered_results, 1):
            print(f"   {i}. {result['file_path']} (ç›¸ä¼¼åº¦: {result['score']:.3f})")
        
        print("=" * 80)
        print("âœ… RAG æ¼”ç¤ºå®Œæˆ")
        print("=" * 80)
        
        return {
            "question": question,
            "answer": answer,
            "sources": filtered_results,
            "context_length": len(context),
            "prompt_length": len(rag_prompt)
        }

async def main():
    print("ğŸš€ RAG-Anything çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    rag = RAGDemo()
    
    # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
    try:
        info = rag.client.get_collection(rag.collection_name)
        print(f"âœ… çŸ¥è¯†åº“çŠ¶æ€: {info.points_count} ä¸ªæ–‡æ¡£å—")
        print(f"ğŸ“– è¯æ±‡è¡¨å¤§å°: {len(rag.vocabulary)} ä¸ªè¯")
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {e}")
        return
    
    # æ¼”ç¤ºé—®é¢˜åˆ—è¡¨
    demo_questions = [
        "Python ç¼–ç¨‹æœ‰ä»€ä¹ˆä¼˜åŠ¿å’Œç‰¹ç‚¹ï¼Ÿ",
        "Docker å®¹å™¨æŠ€æœ¯å¦‚ä½•ä½¿ç”¨ï¼Ÿ",
        "AI Agent çš„ä¸»è¦å®ç°æ–¹å¼æœ‰å“ªäº›ï¼Ÿ",
        "å¦‚ä½•è¿›è¡Œæ•°æ®ç§‘å­¦é¡¹ç›®å¼€å‘ï¼Ÿ"
    ]
    
    print(f"\nğŸ¯ å¼€å§‹ RAG æ¼”ç¤º (å…± {len(demo_questions)} ä¸ªé—®é¢˜)")
    print()
    
    results = []
    
    for i, question in enumerate(demo_questions, 1):
        print(f"ğŸ”¥ æ¼”ç¤º {i}/{len(demo_questions)}")
        
        try:
            result = await rag.demo_rag_process(question)
            if result:
                results.append(result)
            
            # æ¼”ç¤ºé—´éš”
            if i < len(demo_questions):
                print("\nâ±ï¸  ç­‰å¾… 3 ç§’åç»§ç»­ä¸‹ä¸€ä¸ªæ¼”ç¤º...")
                await asyncio.sleep(3)
                
        except Exception as e:
            print(f"âŒ æ¼”ç¤º {i} å¤±è´¥: {e}")
    
    # æ€»ç»“æŠ¥å‘Š
    print("\n" + "=" * 80)
    print("ğŸ“Š RAG æ¼”ç¤ºæ€»ç»“æŠ¥å‘Š")
    print("=" * 80)
    
    if results:
        avg_context_len = sum(r['context_length'] for r in results) / len(results)
        avg_prompt_len = sum(r['prompt_length'] for r in results) / len(results)
        
        print(f"âœ… æˆåŠŸæ¼”ç¤º: {len(results)} ä¸ªé—®é¢˜")
        print(f"ğŸ“ å¹³å‡ä¸Šä¸‹æ–‡é•¿åº¦: {avg_context_len:.0f} å­—ç¬¦")
        print(f"ğŸ’¬ å¹³å‡æç¤ºè¯é•¿åº¦: {avg_prompt_len:.0f} å­—ç¬¦")
        print(f"ğŸ¯ çŸ¥è¯†åº“è¦†ç›–: {info.points_count} ä¸ªæ–‡æ¡£å—")
        
        print(f"\nğŸ“‹ æ¼”ç¤ºé—®é¢˜åˆ—è¡¨:")
        for i, result in enumerate(results, 1):
            print(f"   {i}. {result['question']}")
            print(f"      å›ç­”é•¿åº¦: {len(result['answer'])} å­—ç¬¦")
            print(f"      å‚è€ƒæ–‡æ¡£: {len(result['sources'])} ä¸ª")
    else:
        print("âŒ æ‰€æœ‰æ¼”ç¤ºéƒ½å¤±è´¥äº†")
    
    print("\nğŸ‰ RAG æ¼”ç¤ºå®Œæˆï¼è¿™å°±æ˜¯å®Œæ•´çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæµç¨‹ã€‚")

if __name__ == "__main__":
    asyncio.run(main())