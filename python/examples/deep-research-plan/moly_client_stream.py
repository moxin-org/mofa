import streamlit as st
from openai import OpenAI
import time

# é¡¹ç›®æ ‡é¢˜å’Œåˆå§‹åŒ–
st.set_page_config(page_title="DeepResearchPlanning - AI æ·±åº¦ç ”ç©¶åŠ©æ‰‹", page_icon="ğŸ”")
st.title("ğŸ” DeepResearchPlanning")
st.subheader("æ·±åº¦ç ”ç©¶åŠ©æ‰‹")

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    /* ä¸»å®¹å™¨æ ·å¼ */
    .stApp {
        max-width: 800px;
        margin: 0 auto;
    }
    
    /* èŠå¤©æ¶ˆæ¯æ ·å¼ */
    .user-message {
        background-color: #f0f2f6;
        padding: 12px;
        border-radius: 15px;
        margin: 8px 0;
        max-width: 70%;
        float: right;
        clear: both;
    }
    
    .assistant-message {
        background-color: #e3f2fd;
        padding: 12px;
        border-radius: 15px;
        margin: 8px 0;
        max-width: 70%;
        float: left;
        clear: both;
    }
    
    /* è¾“å…¥æ¡†å®¹å™¨ */
    .input-container {
        position: fixed;
        bottom: 20px;
        width: 70%;
        background: white;
        padding: 20px;
        box-shadow: 0 -2px 10px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–å®¢æˆ·ç«¯å’Œä¼šè¯çŠ¶æ€
if "client" not in st.session_state:
    st.session_state.client = OpenAI(
        base_url="http://127.0.0.1:8000/v3",
        api_key="sk-jsha-1234567890"
    )

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "You are a helpful deep search assistant."},
        {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ·±åº¦ç ”ç©¶åŠ©æ‰‹ï¼Œå¯ä»¥å¸®æ‚¨åˆ†æå„ç§å¤æ‚çš„ç ”ç©¶é—®é¢˜ã€‚è¯·è¾“å…¥æ‚¨çš„ç ”ç©¶ä¸»é¢˜æˆ–é—®é¢˜ã€‚"}
    ]

# æ˜¾ç¤ºèŠå¤©è®°å½•
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(f'<div class="{message["role"]}-message">{message["content"]}</div>',
                        unsafe_allow_html=True)

# ç”¨æˆ·è¾“å…¥å¤„ç†
def generate_response():
    user_input = st.session_state.user_input
    if not user_input.strip():
        return

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    st.session_state.messages.append({"role": "user", "content": user_input})

    try:
        # åˆ›å»ºå ä½ç¬¦ç”¨äºæµå¼è¾“å‡º
        response_placeholder = st.empty()
        full_response = ""

        # è°ƒç”¨APIè·å–æµå¼å“åº”
        response = st.session_state.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=st.session_state.messages,
            stream=True
        )

        # å¤„ç†æµå¼å“åº”
        for chunk in response:
            content = chunk.choices[0].delta.content or ""
            full_response += content
            response_placeholder.markdown(f'<div class="assistant-message">{full_response}â–Œ</div>',
                                          unsafe_allow_html=True)
            time.sleep(0.02)  # æ¨¡æ‹Ÿæµå¼æ•ˆæœ

        # æ›´æ–°æœ€ç»ˆæ˜¾ç¤º
        response_placeholder.markdown(f'<div class="assistant-message">{full_response}</div>',
                                      unsafe_allow_html=True)

        # ä¿å­˜åˆ°å†å²è®°å½•
        st.session_state.messages.append({"role": "assistant", "content": full_response})

    except Exception as e:
        st.error(f"è¯·æ±‚å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
    finally:
        st.session_state.user_input = ""

# è¾“å…¥åŒºåŸŸ
with st.container():
    st.text_input("è¯·è¾“å…¥æ‚¨çš„ç ”ç©¶é—®é¢˜ï¼š",
                  key="user_input",
                  on_change=generate_response,
                  placeholder="åœ¨æ­¤è¾“å…¥æ‚¨çš„ç ”ç©¶é—®é¢˜...",
                  label_visibility="collapsed")